{
  "best_global_step": 14395,
  "best_metric": 0.6261306884173764,
  "best_model_checkpoint": "/scratch/rahlab/vedant/adapt/output/without_adapt/checkpoint-14395",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 14395,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06946856547412296,
      "grad_norm": 12.018725395202637,
      "learning_rate": 2.7361111111111118e-06,
      "loss": 2.331,
      "step": 200
    },
    {
      "epoch": 0.13893713094824592,
      "grad_norm": 14.690415382385254,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.8958,
      "step": 400
    },
    {
      "epoch": 0.2084056964223689,
      "grad_norm": 12.168882369995117,
      "learning_rate": 8.277777777777778e-06,
      "loss": 0.6508,
      "step": 600
    },
    {
      "epoch": 0.27787426189649184,
      "grad_norm": 13.642900466918945,
      "learning_rate": 1.1055555555555557e-05,
      "loss": 0.5331,
      "step": 800
    },
    {
      "epoch": 0.3473428273706148,
      "grad_norm": 8.274724960327148,
      "learning_rate": 1.3833333333333334e-05,
      "loss": 0.4982,
      "step": 1000
    },
    {
      "epoch": 0.4168113928447378,
      "grad_norm": 9.658742904663086,
      "learning_rate": 1.6611111111111113e-05,
      "loss": 0.4797,
      "step": 1200
    },
    {
      "epoch": 0.4862799583188607,
      "grad_norm": 11.304033279418945,
      "learning_rate": 1.938888888888889e-05,
      "loss": 0.4531,
      "step": 1400
    },
    {
      "epoch": 0.5557485237929837,
      "grad_norm": 6.784041404724121,
      "learning_rate": 1.9759166345040527e-05,
      "loss": 0.462,
      "step": 1600
    },
    {
      "epoch": 0.6252170892671066,
      "grad_norm": 6.898079872131348,
      "learning_rate": 1.9450405248938636e-05,
      "loss": 0.4515,
      "step": 1800
    },
    {
      "epoch": 0.6946856547412296,
      "grad_norm": 4.178360939025879,
      "learning_rate": 1.9141644152836745e-05,
      "loss": 0.425,
      "step": 2000
    },
    {
      "epoch": 0.7641542202153525,
      "grad_norm": 7.351629257202148,
      "learning_rate": 1.883288305673485e-05,
      "loss": 0.4089,
      "step": 2200
    },
    {
      "epoch": 0.8336227856894756,
      "grad_norm": 5.767317295074463,
      "learning_rate": 1.8524121960632963e-05,
      "loss": 0.4218,
      "step": 2400
    },
    {
      "epoch": 0.9030913511635985,
      "grad_norm": 4.778557300567627,
      "learning_rate": 1.821536086453107e-05,
      "loss": 0.4238,
      "step": 2600
    },
    {
      "epoch": 0.9725599166377215,
      "grad_norm": 4.836777687072754,
      "learning_rate": 1.790659976842918e-05,
      "loss": 0.4099,
      "step": 2800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8402218205214621,
      "eval_f1": 0.3424160069450398,
      "eval_loss": 0.45077022910118103,
      "eval_matthews_correlation": 0.7947506909727918,
      "eval_precision": 0.35132964681753026,
      "eval_recall": 0.37964448500385445,
      "eval_runtime": 22.4979,
      "eval_samples_per_second": 1450.757,
      "eval_steps_per_second": 22.669,
      "step": 2879
    },
    {
      "epoch": 1.0420284821118444,
      "grad_norm": 5.416642665863037,
      "learning_rate": 1.759783867232729e-05,
      "loss": 0.3957,
      "step": 3000
    },
    {
      "epoch": 1.1114970475859673,
      "grad_norm": 5.980677127838135,
      "learning_rate": 1.7289077576225398e-05,
      "loss": 0.3637,
      "step": 3200
    },
    {
      "epoch": 1.1809656130600903,
      "grad_norm": 5.179112434387207,
      "learning_rate": 1.6980316480123507e-05,
      "loss": 0.3815,
      "step": 3400
    },
    {
      "epoch": 1.2504341785342132,
      "grad_norm": 5.161731719970703,
      "learning_rate": 1.6673099189502123e-05,
      "loss": 0.3803,
      "step": 3600
    },
    {
      "epoch": 1.3199027440083362,
      "grad_norm": 5.559908390045166,
      "learning_rate": 1.6364338093400235e-05,
      "loss": 0.3643,
      "step": 3800
    },
    {
      "epoch": 1.3893713094824591,
      "grad_norm": 4.571346759796143,
      "learning_rate": 1.605557699729834e-05,
      "loss": 0.3807,
      "step": 4000
    },
    {
      "epoch": 1.458839874956582,
      "grad_norm": 3.4444222450256348,
      "learning_rate": 1.574681590119645e-05,
      "loss": 0.3787,
      "step": 4200
    },
    {
      "epoch": 1.5283084404307052,
      "grad_norm": 4.194138526916504,
      "learning_rate": 1.543805480509456e-05,
      "loss": 0.3716,
      "step": 4400
    },
    {
      "epoch": 1.597777005904828,
      "grad_norm": 7.500486373901367,
      "learning_rate": 1.5129293708992667e-05,
      "loss": 0.3568,
      "step": 4600
    },
    {
      "epoch": 1.6672455713789511,
      "grad_norm": 4.659900188446045,
      "learning_rate": 1.4820532612890776e-05,
      "loss": 0.3665,
      "step": 4800
    },
    {
      "epoch": 1.7367141368530739,
      "grad_norm": 6.9575700759887695,
      "learning_rate": 1.4513315322269395e-05,
      "loss": 0.3644,
      "step": 5000
    },
    {
      "epoch": 1.806182702327197,
      "grad_norm": 2.902416467666626,
      "learning_rate": 1.4204554226167504e-05,
      "loss": 0.3606,
      "step": 5200
    },
    {
      "epoch": 1.8756512678013197,
      "grad_norm": 6.43427848815918,
      "learning_rate": 1.3895793130065613e-05,
      "loss": 0.3514,
      "step": 5400
    },
    {
      "epoch": 1.945119833275443,
      "grad_norm": 6.020069122314453,
      "learning_rate": 1.358703203396372e-05,
      "loss": 0.359,
      "step": 5600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.864548546217715,
      "eval_f1": 0.5444008689810031,
      "eval_loss": 0.3758213520050049,
      "eval_matthews_correlation": 0.8268624801792605,
      "eval_precision": 0.5863037738269893,
      "eval_recall": 0.5536857587466217,
      "eval_runtime": 22.3398,
      "eval_samples_per_second": 1461.024,
      "eval_steps_per_second": 22.829,
      "step": 5758
    },
    {
      "epoch": 2.0145883987495656,
      "grad_norm": 7.819921970367432,
      "learning_rate": 1.3278270937861831e-05,
      "loss": 0.3393,
      "step": 5800
    },
    {
      "epoch": 2.084056964223689,
      "grad_norm": 3.6136603355407715,
      "learning_rate": 1.296950984175994e-05,
      "loss": 0.3191,
      "step": 6000
    },
    {
      "epoch": 2.153525529697812,
      "grad_norm": 8.038743019104004,
      "learning_rate": 1.2660748745658049e-05,
      "loss": 0.3081,
      "step": 6200
    },
    {
      "epoch": 2.2229940951719347,
      "grad_norm": 6.380909442901611,
      "learning_rate": 1.2351987649556156e-05,
      "loss": 0.3138,
      "step": 6400
    },
    {
      "epoch": 2.2924626606460574,
      "grad_norm": 4.035409927368164,
      "learning_rate": 1.2043226553454267e-05,
      "loss": 0.3129,
      "step": 6600
    },
    {
      "epoch": 2.3619312261201806,
      "grad_norm": 11.151540756225586,
      "learning_rate": 1.1734465457352375e-05,
      "loss": 0.3081,
      "step": 6800
    },
    {
      "epoch": 2.4313997915943037,
      "grad_norm": 6.238368034362793,
      "learning_rate": 1.1425704361250483e-05,
      "loss": 0.3164,
      "step": 7000
    },
    {
      "epoch": 2.5008683570684265,
      "grad_norm": 5.873220443725586,
      "learning_rate": 1.1116943265148592e-05,
      "loss": 0.3111,
      "step": 7200
    },
    {
      "epoch": 2.5703369225425496,
      "grad_norm": 5.172582149505615,
      "learning_rate": 1.0808182169046702e-05,
      "loss": 0.3166,
      "step": 7400
    },
    {
      "epoch": 2.6398054880166724,
      "grad_norm": 5.419054985046387,
      "learning_rate": 1.049942107294481e-05,
      "loss": 0.3116,
      "step": 7600
    },
    {
      "epoch": 2.7092740534907955,
      "grad_norm": 6.7550950050354,
      "learning_rate": 1.0190659976842918e-05,
      "loss": 0.3007,
      "step": 7800
    },
    {
      "epoch": 2.7787426189649183,
      "grad_norm": 11.004526138305664,
      "learning_rate": 9.883442686221537e-06,
      "loss": 0.3115,
      "step": 8000
    },
    {
      "epoch": 2.8482111844390414,
      "grad_norm": 6.04899787902832,
      "learning_rate": 9.574681590119646e-06,
      "loss": 0.3049,
      "step": 8200
    },
    {
      "epoch": 2.917679749913164,
      "grad_norm": 6.990269660949707,
      "learning_rate": 9.265920494017755e-06,
      "loss": 0.3078,
      "step": 8400
    },
    {
      "epoch": 2.9871483153872873,
      "grad_norm": 4.622071266174316,
      "learning_rate": 8.957159397915864e-06,
      "loss": 0.2971,
      "step": 8600
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8703085266092712,
      "eval_f1": 0.5905901505021691,
      "eval_loss": 0.37322497367858887,
      "eval_matthews_correlation": 0.8335073660022384,
      "eval_precision": 0.6007081006342939,
      "eval_recall": 0.5957061095210674,
      "eval_runtime": 22.4727,
      "eval_samples_per_second": 1452.381,
      "eval_steps_per_second": 22.694,
      "step": 8637
    },
    {
      "epoch": 3.05661688086141,
      "grad_norm": 4.8017096519470215,
      "learning_rate": 8.648398301813971e-06,
      "loss": 0.2773,
      "step": 8800
    },
    {
      "epoch": 3.126085446335533,
      "grad_norm": 9.566496849060059,
      "learning_rate": 8.339637205712082e-06,
      "loss": 0.2672,
      "step": 9000
    },
    {
      "epoch": 3.195554011809656,
      "grad_norm": 10.856249809265137,
      "learning_rate": 8.030876109610189e-06,
      "loss": 0.2747,
      "step": 9200
    },
    {
      "epoch": 3.265022577283779,
      "grad_norm": 7.62664794921875,
      "learning_rate": 7.7221150135083e-06,
      "loss": 0.2768,
      "step": 9400
    },
    {
      "epoch": 3.3344911427579023,
      "grad_norm": 6.852026462554932,
      "learning_rate": 7.413353917406407e-06,
      "loss": 0.2717,
      "step": 9600
    },
    {
      "epoch": 3.403959708232025,
      "grad_norm": 7.3568315505981445,
      "learning_rate": 7.104592821304516e-06,
      "loss": 0.2635,
      "step": 9800
    },
    {
      "epoch": 3.473428273706148,
      "grad_norm": 9.53476333618164,
      "learning_rate": 6.7958317252026255e-06,
      "loss": 0.2697,
      "step": 10000
    },
    {
      "epoch": 3.542896839180271,
      "grad_norm": 11.201591491699219,
      "learning_rate": 6.487070629100734e-06,
      "loss": 0.2618,
      "step": 10200
    },
    {
      "epoch": 3.612365404654394,
      "grad_norm": 8.378997802734375,
      "learning_rate": 6.178309532998843e-06,
      "loss": 0.2601,
      "step": 10400
    },
    {
      "epoch": 3.6818339701285168,
      "grad_norm": 6.533530235290527,
      "learning_rate": 5.869548436896951e-06,
      "loss": 0.2729,
      "step": 10600
    },
    {
      "epoch": 3.75130253560264,
      "grad_norm": 5.447280406951904,
      "learning_rate": 5.560787340795061e-06,
      "loss": 0.283,
      "step": 10800
    },
    {
      "epoch": 3.8207711010767627,
      "grad_norm": 7.717545032501221,
      "learning_rate": 5.252026244693169e-06,
      "loss": 0.2615,
      "step": 11000
    },
    {
      "epoch": 3.890239666550886,
      "grad_norm": 3.8513689041137695,
      "learning_rate": 4.943265148591278e-06,
      "loss": 0.2692,
      "step": 11200
    },
    {
      "epoch": 3.9597082320250085,
      "grad_norm": 4.747395992279053,
      "learning_rate": 4.634504052489387e-06,
      "loss": 0.2683,
      "step": 11400
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8735868133214866,
      "eval_f1": 0.6185091092989298,
      "eval_loss": 0.37437891960144043,
      "eval_matthews_correlation": 0.83807045002978,
      "eval_precision": 0.6168682088256296,
      "eval_recall": 0.6293361913345156,
      "eval_runtime": 22.2957,
      "eval_samples_per_second": 1463.915,
      "eval_steps_per_second": 22.874,
      "step": 11516
    },
    {
      "epoch": 4.029176797499131,
      "grad_norm": 9.598688125610352,
      "learning_rate": 4.325742956387495e-06,
      "loss": 0.2558,
      "step": 11600
    },
    {
      "epoch": 4.098645362973254,
      "grad_norm": 6.395835876464844,
      "learning_rate": 4.016981860285604e-06,
      "loss": 0.2428,
      "step": 11800
    },
    {
      "epoch": 4.168113928447378,
      "grad_norm": 8.10587215423584,
      "learning_rate": 3.7082207641837133e-06,
      "loss": 0.239,
      "step": 12000
    },
    {
      "epoch": 4.237582493921501,
      "grad_norm": 7.433152198791504,
      "learning_rate": 3.4010034735623315e-06,
      "loss": 0.2487,
      "step": 12200
    },
    {
      "epoch": 4.307051059395624,
      "grad_norm": 5.318507194519043,
      "learning_rate": 3.0922423774604404e-06,
      "loss": 0.2471,
      "step": 12400
    },
    {
      "epoch": 4.376519624869746,
      "grad_norm": 9.082423210144043,
      "learning_rate": 2.783481281358549e-06,
      "loss": 0.2385,
      "step": 12600
    },
    {
      "epoch": 4.445988190343869,
      "grad_norm": 8.362955093383789,
      "learning_rate": 2.474720185256658e-06,
      "loss": 0.2401,
      "step": 12800
    },
    {
      "epoch": 4.5154567558179926,
      "grad_norm": 7.612619876861572,
      "learning_rate": 2.1659590891547667e-06,
      "loss": 0.2401,
      "step": 13000
    },
    {
      "epoch": 4.584925321292115,
      "grad_norm": 13.633018493652344,
      "learning_rate": 1.8571979930528756e-06,
      "loss": 0.2377,
      "step": 13200
    },
    {
      "epoch": 4.654393886766238,
      "grad_norm": 2.8719348907470703,
      "learning_rate": 1.5484368969509845e-06,
      "loss": 0.2292,
      "step": 13400
    },
    {
      "epoch": 4.723862452240361,
      "grad_norm": 9.660489082336426,
      "learning_rate": 1.239675800849093e-06,
      "loss": 0.2338,
      "step": 13600
    },
    {
      "epoch": 4.793331017714484,
      "grad_norm": 11.933306694030762,
      "learning_rate": 9.30914704747202e-07,
      "loss": 0.231,
      "step": 13800
    },
    {
      "epoch": 4.8627995831886075,
      "grad_norm": 6.357919216156006,
      "learning_rate": 6.221536086453108e-07,
      "loss": 0.239,
      "step": 14000
    },
    {
      "epoch": 4.93226814866273,
      "grad_norm": 8.42728042602539,
      "learning_rate": 3.1493631802392897e-07,
      "loss": 0.225,
      "step": 14200
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8738012806764913,
      "eval_f1": 0.6261306884173764,
      "eval_loss": 0.3903249502182007,
      "eval_matthews_correlation": 0.8382732154321557,
      "eval_precision": 0.6260246640726692,
      "eval_recall": 0.6322805029256714,
      "eval_runtime": 22.3206,
      "eval_samples_per_second": 1462.283,
      "eval_steps_per_second": 22.849,
      "step": 14395
    }
  ],
  "logging_steps": 200,
  "max_steps": 14395,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4243377311370445e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
