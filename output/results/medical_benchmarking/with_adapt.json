{
  "best_global_step": 14395,
  "best_metric": 0.6361830367250897,
  "best_model_checkpoint": "/scratch/rahlab/vedant/adapt/output/with_adapt/checkpoint-14395",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 14395,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06946856547412296,
      "grad_norm": 11.992193222045898,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 2.372,
      "step": 200
    },
    {
      "epoch": 0.13893713094824592,
      "grad_norm": 12.282303810119629,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.9071,
      "step": 400
    },
    {
      "epoch": 0.2084056964223689,
      "grad_norm": 13.08842658996582,
      "learning_rate": 8.277777777777778e-06,
      "loss": 0.6425,
      "step": 600
    },
    {
      "epoch": 0.27787426189649184,
      "grad_norm": 9.900371551513672,
      "learning_rate": 1.1055555555555557e-05,
      "loss": 0.5446,
      "step": 800
    },
    {
      "epoch": 0.3473428273706148,
      "grad_norm": 9.098176956176758,
      "learning_rate": 1.3833333333333334e-05,
      "loss": 0.5098,
      "step": 1000
    },
    {
      "epoch": 0.4168113928447378,
      "grad_norm": 8.576056480407715,
      "learning_rate": 1.6611111111111113e-05,
      "loss": 0.4862,
      "step": 1200
    },
    {
      "epoch": 0.4862799583188607,
      "grad_norm": 11.396240234375,
      "learning_rate": 1.938888888888889e-05,
      "loss": 0.4579,
      "step": 1400
    },
    {
      "epoch": 0.5557485237929837,
      "grad_norm": 7.116296768188477,
      "learning_rate": 1.9759166345040527e-05,
      "loss": 0.4657,
      "step": 1600
    },
    {
      "epoch": 0.6252170892671066,
      "grad_norm": 6.479680061340332,
      "learning_rate": 1.9450405248938636e-05,
      "loss": 0.4527,
      "step": 1800
    },
    {
      "epoch": 0.6946856547412296,
      "grad_norm": 5.077436447143555,
      "learning_rate": 1.914318795831725e-05,
      "loss": 0.433,
      "step": 2000
    },
    {
      "epoch": 0.7641542202153525,
      "grad_norm": 3.886033535003662,
      "learning_rate": 1.8834426862215364e-05,
      "loss": 0.4156,
      "step": 2200
    },
    {
      "epoch": 0.8336227856894756,
      "grad_norm": 10.96568489074707,
      "learning_rate": 1.8525665766113473e-05,
      "loss": 0.4247,
      "step": 2400
    },
    {
      "epoch": 0.9030913511635985,
      "grad_norm": 5.430473804473877,
      "learning_rate": 1.821690467001158e-05,
      "loss": 0.4274,
      "step": 2600
    },
    {
      "epoch": 0.9725599166377215,
      "grad_norm": 9.612053871154785,
      "learning_rate": 1.7908143573909687e-05,
      "loss": 0.4125,
      "step": 2800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8423358558779375,
      "eval_f1": 0.3764232049273012,
      "eval_loss": 0.43536531925201416,
      "eval_matthews_correlation": 0.7971066439936514,
      "eval_precision": 0.38382487964913625,
      "eval_recall": 0.4023432881025582,
      "eval_runtime": 22.2508,
      "eval_samples_per_second": 1466.87,
      "eval_steps_per_second": 22.921,
      "step": 2879
    },
    {
      "epoch": 1.0420284821118444,
      "grad_norm": 5.317570686340332,
      "learning_rate": 1.75993824778078e-05,
      "loss": 0.3954,
      "step": 3000
    },
    {
      "epoch": 1.1114970475859673,
      "grad_norm": 5.903696537017822,
      "learning_rate": 1.7290621381705905e-05,
      "loss": 0.3635,
      "step": 3200
    },
    {
      "epoch": 1.1809656130600903,
      "grad_norm": 5.618144512176514,
      "learning_rate": 1.6981860285604014e-05,
      "loss": 0.3832,
      "step": 3400
    },
    {
      "epoch": 1.2504341785342132,
      "grad_norm": 5.220486640930176,
      "learning_rate": 1.6673099189502123e-05,
      "loss": 0.3814,
      "step": 3600
    },
    {
      "epoch": 1.3199027440083362,
      "grad_norm": 7.300841808319092,
      "learning_rate": 1.6364338093400235e-05,
      "loss": 0.3616,
      "step": 3800
    },
    {
      "epoch": 1.3893713094824591,
      "grad_norm": 5.420657157897949,
      "learning_rate": 1.605557699729834e-05,
      "loss": 0.378,
      "step": 4000
    },
    {
      "epoch": 1.458839874956582,
      "grad_norm": 3.4084525108337402,
      "learning_rate": 1.574681590119645e-05,
      "loss": 0.3764,
      "step": 4200
    },
    {
      "epoch": 1.5283084404307052,
      "grad_norm": 4.416626930236816,
      "learning_rate": 1.543805480509456e-05,
      "loss": 0.3685,
      "step": 4400
    },
    {
      "epoch": 1.597777005904828,
      "grad_norm": 7.840156078338623,
      "learning_rate": 1.5129293708992667e-05,
      "loss": 0.3557,
      "step": 4600
    },
    {
      "epoch": 1.6672455713789511,
      "grad_norm": 6.8706254959106445,
      "learning_rate": 1.4820532612890776e-05,
      "loss": 0.3677,
      "step": 4800
    },
    {
      "epoch": 1.7367141368530739,
      "grad_norm": 6.828648090362549,
      "learning_rate": 1.4511771516788887e-05,
      "loss": 0.3593,
      "step": 5000
    },
    {
      "epoch": 1.806182702327197,
      "grad_norm": 4.6175737380981445,
      "learning_rate": 1.4203010420686996e-05,
      "loss": 0.364,
      "step": 5200
    },
    {
      "epoch": 1.8756512678013197,
      "grad_norm": 9.284499168395996,
      "learning_rate": 1.3894249324585103e-05,
      "loss": 0.3528,
      "step": 5400
    },
    {
      "epoch": 1.945119833275443,
      "grad_norm": 6.027324676513672,
      "learning_rate": 1.3585488228483212e-05,
      "loss": 0.3585,
      "step": 5600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8680719384785073,
      "eval_f1": 0.596015244980111,
      "eval_loss": 0.370949923992157,
      "eval_matthews_correlation": 0.8312854099000937,
      "eval_precision": 0.6189748912012399,
      "eval_recall": 0.5883951417509825,
      "eval_runtime": 22.231,
      "eval_samples_per_second": 1468.172,
      "eval_steps_per_second": 22.941,
      "step": 5758
    },
    {
      "epoch": 2.0145883987495656,
      "grad_norm": 11.410202026367188,
      "learning_rate": 1.3276727132381322e-05,
      "loss": 0.3418,
      "step": 5800
    },
    {
      "epoch": 2.084056964223689,
      "grad_norm": 5.362612247467041,
      "learning_rate": 1.296796603627943e-05,
      "loss": 0.3203,
      "step": 6000
    },
    {
      "epoch": 2.153525529697812,
      "grad_norm": 9.459900856018066,
      "learning_rate": 1.2660748745658049e-05,
      "loss": 0.3142,
      "step": 6200
    },
    {
      "epoch": 2.2229940951719347,
      "grad_norm": 5.5447001457214355,
      "learning_rate": 1.2351987649556156e-05,
      "loss": 0.3126,
      "step": 6400
    },
    {
      "epoch": 2.2924626606460574,
      "grad_norm": 6.8611159324646,
      "learning_rate": 1.2043226553454267e-05,
      "loss": 0.3156,
      "step": 6600
    },
    {
      "epoch": 2.3619312261201806,
      "grad_norm": 6.752880573272705,
      "learning_rate": 1.1734465457352375e-05,
      "loss": 0.3095,
      "step": 6800
    },
    {
      "epoch": 2.4313997915943037,
      "grad_norm": 6.016089916229248,
      "learning_rate": 1.1425704361250483e-05,
      "loss": 0.317,
      "step": 7000
    },
    {
      "epoch": 2.5008683570684265,
      "grad_norm": 7.83941650390625,
      "learning_rate": 1.1116943265148592e-05,
      "loss": 0.3149,
      "step": 7200
    },
    {
      "epoch": 2.5703369225425496,
      "grad_norm": 6.054992198944092,
      "learning_rate": 1.0808182169046702e-05,
      "loss": 0.3236,
      "step": 7400
    },
    {
      "epoch": 2.6398054880166724,
      "grad_norm": 6.940295696258545,
      "learning_rate": 1.049942107294481e-05,
      "loss": 0.3137,
      "step": 7600
    },
    {
      "epoch": 2.7092740534907955,
      "grad_norm": 8.071532249450684,
      "learning_rate": 1.0190659976842918e-05,
      "loss": 0.3026,
      "step": 7800
    },
    {
      "epoch": 2.7787426189649183,
      "grad_norm": 7.625051975250244,
      "learning_rate": 9.881898880741027e-06,
      "loss": 0.3158,
      "step": 8000
    },
    {
      "epoch": 2.8482111844390414,
      "grad_norm": 7.223959445953369,
      "learning_rate": 9.573137784639136e-06,
      "loss": 0.303,
      "step": 8200
    },
    {
      "epoch": 2.917679749913164,
      "grad_norm": 5.221193313598633,
      "learning_rate": 9.264376688537245e-06,
      "loss": 0.3143,
      "step": 8400
    },
    {
      "epoch": 2.9871483153872873,
      "grad_norm": 6.9507832527160645,
      "learning_rate": 8.955615592435354e-06,
      "loss": 0.2992,
      "step": 8600
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8727902202886118,
      "eval_f1": 0.6223873403192115,
      "eval_loss": 0.36782145500183105,
      "eval_matthews_correlation": 0.836615129222493,
      "eval_precision": 0.619956632193688,
      "eval_recall": 0.6313735354234516,
      "eval_runtime": 22.1803,
      "eval_samples_per_second": 1471.532,
      "eval_steps_per_second": 22.993,
      "step": 8637
    },
    {
      "epoch": 3.05661688086141,
      "grad_norm": 6.598031520843506,
      "learning_rate": 8.646854496333463e-06,
      "loss": 0.2797,
      "step": 8800
    },
    {
      "epoch": 3.126085446335533,
      "grad_norm": 5.355802059173584,
      "learning_rate": 8.338093400231572e-06,
      "loss": 0.2746,
      "step": 9000
    },
    {
      "epoch": 3.195554011809656,
      "grad_norm": 10.312010765075684,
      "learning_rate": 8.030876109610189e-06,
      "loss": 0.2824,
      "step": 9200
    },
    {
      "epoch": 3.265022577283779,
      "grad_norm": 9.056118965148926,
      "learning_rate": 7.7221150135083e-06,
      "loss": 0.2748,
      "step": 9400
    },
    {
      "epoch": 3.3344911427579023,
      "grad_norm": 12.874710083007812,
      "learning_rate": 7.413353917406407e-06,
      "loss": 0.2769,
      "step": 9600
    },
    {
      "epoch": 3.403959708232025,
      "grad_norm": 7.8333964347839355,
      "learning_rate": 7.104592821304516e-06,
      "loss": 0.2633,
      "step": 9800
    },
    {
      "epoch": 3.473428273706148,
      "grad_norm": 6.655458450317383,
      "learning_rate": 6.7958317252026255e-06,
      "loss": 0.2716,
      "step": 10000
    },
    {
      "epoch": 3.542896839180271,
      "grad_norm": 10.560035705566406,
      "learning_rate": 6.487070629100734e-06,
      "loss": 0.2639,
      "step": 10200
    },
    {
      "epoch": 3.612365404654394,
      "grad_norm": 8.139845848083496,
      "learning_rate": 6.178309532998843e-06,
      "loss": 0.2662,
      "step": 10400
    },
    {
      "epoch": 3.6818339701285168,
      "grad_norm": 7.748180866241455,
      "learning_rate": 5.869548436896951e-06,
      "loss": 0.2712,
      "step": 10600
    },
    {
      "epoch": 3.75130253560264,
      "grad_norm": 4.614923477172852,
      "learning_rate": 5.560787340795061e-06,
      "loss": 0.2876,
      "step": 10800
    },
    {
      "epoch": 3.8207711010767627,
      "grad_norm": 4.9747138023376465,
      "learning_rate": 5.252026244693169e-06,
      "loss": 0.2659,
      "step": 11000
    },
    {
      "epoch": 3.890239666550886,
      "grad_norm": 5.668099403381348,
      "learning_rate": 4.9448089540717875e-06,
      "loss": 0.2727,
      "step": 11200
    },
    {
      "epoch": 3.9597082320250085,
      "grad_norm": 5.577978134155273,
      "learning_rate": 4.636047857969896e-06,
      "loss": 0.2723,
      "step": 11400
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8723306473850302,
      "eval_f1": 0.6331527426201671,
      "eval_loss": 0.3789960741996765,
      "eval_matthews_correlation": 0.836466597445383,
      "eval_precision": 0.6311679411070755,
      "eval_recall": 0.6497836538688762,
      "eval_runtime": 22.1926,
      "eval_samples_per_second": 1470.717,
      "eval_steps_per_second": 22.981,
      "step": 11516
    },
    {
      "epoch": 4.029176797499131,
      "grad_norm": 7.659371852874756,
      "learning_rate": 4.327286761868004e-06,
      "loss": 0.2595,
      "step": 11600
    },
    {
      "epoch": 4.098645362973254,
      "grad_norm": 7.692148685455322,
      "learning_rate": 4.018525665766113e-06,
      "loss": 0.2475,
      "step": 11800
    },
    {
      "epoch": 4.168113928447378,
      "grad_norm": 7.236469745635986,
      "learning_rate": 3.7097645696642226e-06,
      "loss": 0.2413,
      "step": 12000
    },
    {
      "epoch": 4.237582493921501,
      "grad_norm": 9.85061264038086,
      "learning_rate": 3.4010034735623315e-06,
      "loss": 0.2508,
      "step": 12200
    },
    {
      "epoch": 4.307051059395624,
      "grad_norm": 12.725852966308594,
      "learning_rate": 3.0922423774604404e-06,
      "loss": 0.249,
      "step": 12400
    },
    {
      "epoch": 4.376519624869746,
      "grad_norm": 9.677315711975098,
      "learning_rate": 2.783481281358549e-06,
      "loss": 0.2462,
      "step": 12600
    },
    {
      "epoch": 4.445988190343869,
      "grad_norm": 6.610694408416748,
      "learning_rate": 2.474720185256658e-06,
      "loss": 0.242,
      "step": 12800
    },
    {
      "epoch": 4.5154567558179926,
      "grad_norm": 7.538276672363281,
      "learning_rate": 2.1659590891547667e-06,
      "loss": 0.2443,
      "step": 13000
    },
    {
      "epoch": 4.584925321292115,
      "grad_norm": 6.7251386642456055,
      "learning_rate": 1.8571979930528756e-06,
      "loss": 0.2399,
      "step": 13200
    },
    {
      "epoch": 4.654393886766238,
      "grad_norm": 3.510753631591797,
      "learning_rate": 1.5484368969509845e-06,
      "loss": 0.2347,
      "step": 13400
    },
    {
      "epoch": 4.723862452240361,
      "grad_norm": 8.866744995117188,
      "learning_rate": 1.239675800849093e-06,
      "loss": 0.2348,
      "step": 13600
    },
    {
      "epoch": 4.793331017714484,
      "grad_norm": 5.442460536956787,
      "learning_rate": 9.324585102277115e-07,
      "loss": 0.2334,
      "step": 13800
    },
    {
      "epoch": 4.8627995831886075,
      "grad_norm": 5.423186779022217,
      "learning_rate": 6.236974141258202e-07,
      "loss": 0.2455,
      "step": 14000
    },
    {
      "epoch": 4.93226814866273,
      "grad_norm": 11.842549324035645,
      "learning_rate": 3.1493631802392897e-07,
      "loss": 0.2269,
      "step": 14200
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8746285119029382,
      "eval_f1": 0.6361830367250897,
      "eval_loss": 0.3922916054725647,
      "eval_matthews_correlation": 0.8392361306312589,
      "eval_precision": 0.6367658833788364,
      "eval_recall": 0.6421839312309747,
      "eval_runtime": 22.2474,
      "eval_samples_per_second": 1467.09,
      "eval_steps_per_second": 22.924,
      "step": 14395
    }
  ],
  "logging_steps": 200,
  "max_steps": 14395,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.4243377311370445e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
